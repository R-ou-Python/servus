{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json, spacy, pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateGenerator():\n",
    "    def __init__(self):\n",
    "        self.templates = json.load(open(r'../data/interim/templates.json', 'r', encoding='utf-8'))\n",
    "        entidades = json.load(open(r'../data/interim/ents_para_template.json', 'r', encoding='latin9'))\n",
    "        with open(r'../data/interim/despesapessoal.txt', 'r', encoding='utf-8') as f:\n",
    "            self.despesa_pessoal = set([x.replace('\\n','') for x in f.readlines() if x])\n",
    "        with open(r'../data/interim/despesapublica.txt', 'r', encoding='utf-8') as f:\n",
    "            self.despesa_publica = set([x.replace('\\n','') for x in f.readlines() if x])\n",
    "        with open(r'../data/interim/substantivos.txt', 'r', encoding='latin9') as f:\n",
    "            self.substantivos = list(set([x.replace('\\n','') for x in f.readlines() if x]))\n",
    "            self.substantivos = list(filter(lambda x:x not in self.despesa_pessoal and x not in self.despesa_publica, \n",
    "                                       self.substantivos))\n",
    "        \n",
    "        self.utterances = {}\n",
    "        self.utterances['DESPESAPESSOAL'] = []\n",
    "        self.utterances['DESPESAPUBLICA'] = []\n",
    "        self.utterances['GENERICA'] = []\n",
    "        \n",
    "    def generate(self):\n",
    "        # pessoal\n",
    "        self.tpessoal = self.templates['DESPESAPESSOAL']\n",
    "        for t in self.tpessoal:\n",
    "            for d in self.despesa_pessoal:\n",
    "                self.utterances['DESPESAPESSOAL'].append(t.replace('{ENTIDADE}',d))\n",
    "                \n",
    "        self.tpublica = self.templates['DESPESAPUBLICA']\n",
    "        for t in self.tpublica:\n",
    "            for d in self.despesa_publica:\n",
    "                self.utterances['DESPESAPUBLICA'].append(t.replace('{ENTIDADE}',d))\n",
    "                \n",
    "        len_generica = max(len(self.utterances['DESPESAPUBLICA']), len(self.utterances['DESPESAPESSOAL']))\n",
    "        tgen = self.tpessoal + self.tpublica\n",
    "        for _ in range(len_generica):\n",
    "            t = random.choice(tgen)\n",
    "            s = random.choice(self.substantivos)\n",
    "            self.utterances['GENERICA'].append(t.replace('{ENTIDADE}',s))\n",
    "            \n",
    "    def save(self):\n",
    "        with open(r'../data/interim/utterances.json', 'w', encoding='utf-8') as fp:\n",
    "            fp.write(json.dumps(self.utterances, indent=2, ensure_ascii=False))\n",
    "            \n",
    "    def save_train_data(self):\n",
    "        self.train_data = []\n",
    "        \n",
    "        self.tpessoal = self.templates['DESPESAPESSOAL']\n",
    "        for t in self.tpessoal:\n",
    "            for d in self.despesa_pessoal:\n",
    "                cnt = t.replace('{ENTIDADE}',d)\n",
    "                edict = {'entities':[(cnt.find(d),cnt.find(d)+len(d),\"CONTROLEEXTERNO\")]}\n",
    "                self.train_data.append((cnt, edict))\n",
    "                \n",
    "                \n",
    "        self.tpublica = self.templates['DESPESAPUBLICA']\n",
    "        for t in self.tpublica:\n",
    "            for d in self.despesa_publica:\n",
    "                cnt = t.replace('{ENTIDADE}',d)\n",
    "                edict = {'entities':[(cnt.find(d),cnt.find(d)+len(d),\"CONTROLEEXTERNO\")]}\n",
    "                self.train_data.append((cnt, edict))\n",
    "        \n",
    "        with open(r'../data/interim/synth_train_data.pkl', 'wb') as fp:\n",
    "            pickle.dump(self.train_data, fp)\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TemplateGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geração do embedding específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data\\gazetteers\\despesapessoal.txt', 'r', encoding='utf-8') as f:\n",
    "    despesa_pessoal = set([x.replace('\\n','') for x in f.readlines() if x])\n",
    "with open(r'data\\gazetteers\\despesapublica.txt', 'r', encoding='utf-8') as f:\n",
    "    despesa_publica = set([x.replace('\\n','') for x in f.readlines() if x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazetteers = list(despesa_pessoal) + list(despesa_publica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.pt.Portuguese at 0x1eb68a2cb38>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[str(x) for x in nlp(g)] for g in gazetteers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, min_count=1, size=30, workers=3, window=2, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.6278040e-03, -5.4667559e-03, -2.3543884e-03,  1.3274187e-02,\n",
       "        1.2416037e-03,  5.1690312e-03,  1.6006805e-02, -1.2449811e-02,\n",
       "        2.3562612e-03,  1.6510904e-02,  7.8101526e-03, -1.3202942e-02,\n",
       "        1.6252829e-02, -9.7082760e-03,  8.5476117e-05, -7.3867482e-03,\n",
       "       -8.7993629e-03,  8.7538036e-03, -1.6177714e-02, -1.1851009e-02,\n",
       "        1.5232809e-02, -1.0236542e-02,  1.2112031e-02, -7.2901375e-03,\n",
       "       -4.4440348e-03,  7.0926524e-04,  1.6374322e-02,  8.4237223e-03,\n",
       "        1.4730961e-02, -1.0998782e-02], dtype=float32)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['siai-dp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(r'data\\wordemb\\specific.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
